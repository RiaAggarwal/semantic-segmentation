{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /tmp/xdg-cache/torch/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:20<00:00, 26.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "from torchvision import utils\n",
    "# from basic_fcn import *\n",
    "from model_to_run import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pprint import pprint\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CityScapesDataset(csv_file='./Data/train.csv')\n",
    "val_dataset = CityScapesDataset(csv_file='./Data/val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='./Data/test.csv')\n",
    "\n",
    "_batch_size = 4\n",
    "_num_workers = 4\n",
    "iou_classes = [11, 20, 24, 26, 33]\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=_batch_size,\n",
    "                          num_workers=_num_workers,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=1,\n",
    "                          num_workers=_num_workers,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=1,\n",
    "                          num_workers=_num_workers,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        #torch.nn.init.xavier_uniform(m.bias.data)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "epochs     = 1000\n",
    "criterion = nn.CrossEntropyLoss()# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "model = modelToRun\n",
    "# for name, params in fcn_model.named_parameters():\n",
    "#     print(name, params.shape, params.requires_grad)\n",
    "    \n",
    "model.apply(init_weights)\n",
    "#fcn_model = torch.load('best_model')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created folder :  ./Results/vgg_with_checkpoints\n"
     ]
    }
   ],
   "source": [
    "modelName = modelNameSpace\n",
    "MYDIR = \"./Results\" + \"/\" + modelName\n",
    "CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MYDIR)\n",
    "    print(\"created folder : \", MYDIR)\n",
    "else:\n",
    "    print(MYDIR, \"folder already exists.\")\n",
    "\n",
    "def plotTwoGraphs(base, train_metrics, val_metrics):\n",
    "    plt.figure()\n",
    "    plt.plot(base, train_metrics)\n",
    "    plt.plot(base, val_metrics)\n",
    "    plt.gca().legend(('train','validation'))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.savefig(MYDIR + '/loss.png')\n",
    "\n",
    "def plotGraph(base, metrics, name):\n",
    "    plt.figure()\n",
    "    plt.plot(base, metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(name)\n",
    "    plt.title(name + ' vs Epochs')\n",
    "    plt.savefig(MYDIR + '/' + name + '.png')\n",
    "    \n",
    "def plotIousClassWise(base, d):\n",
    "    plt.figure()\n",
    "    legends = []\n",
    "    for c in iou_classes:\n",
    "        plt.plot(base, d[c])\n",
    "        legends.append(idsNames[c])\n",
    "    plt.gca().legend(tuple(legends))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('IOU Class Wise')\n",
    "    plt.title('Loss vs Class Wise IOU')\n",
    "    plt.savefig(MYDIR + '/class_wise_ious.png')\n",
    "        #plotGraph([i for i in range(epoch+1)], all_val_iou_class[c], 'iou_'+idsNames[c]+'')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33]\n",
      "epoch0, iter0, loss: 4.19533634185791\n",
      "epoch0, iter100, loss: 1.8589003086090088\n",
      "epoch0, iter200, loss: 1.7201731204986572\n",
      "epoch0, iter300, loss: 1.6979961395263672\n",
      "epoch0, iter400, loss: 1.0934609174728394\n",
      "epoch0, iter500, loss: 1.6762423515319824\n",
      "epoch0, iter600, loss: 1.663445234298706\n",
      "epoch0, iter700, loss: 1.9572975635528564\n",
      "training loss :  1.9415429674329296\n",
      "Finish epoch 0, time elapsed 140.33882236480713\n",
      "Validation loss after epoch 0, , loss: 1.7416761401593686\n",
      "Accuracy on val after epoch 0, accuracy: 50.58628333656264\n",
      "IOU for class 11 on val after epoch0, iou: 9.418636371212905\n",
      "IOU for class 20 on val after epoch0, iou: 0.0\n",
      "IOU for class 24 on val after epoch0, iou: 4.566221113067317\n",
      "IOU for class 26 on val after epoch0, iou: 0.0\n",
      "IOU for class 33 on val after epoch0, iou: 0.0\n",
      "{7: 0.5303941691930991, 8: 0.0, 11: 0.09418636371212905, 12: 0.0, 13: 0.0, 17: 0.0, 19: 0.0, 20: 0.0, 21: 0.08083898414360342, 22: 0.0, 23: 0.0, 24: 0.045662211130673175, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 31: 0.0, 32: 0.0, 33: 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved for later use\n",
      "epoch1, iter0, loss: 1.9302451610565186\n",
      "epoch1, iter100, loss: 1.8293017148971558\n",
      "epoch1, iter200, loss: 1.2801700830459595\n",
      "epoch1, iter300, loss: 2.0891246795654297\n",
      "epoch1, iter400, loss: 0.9370379447937012\n",
      "epoch1, iter500, loss: 2.0283074378967285\n",
      "epoch1, iter600, loss: 1.3774946928024292\n",
      "epoch1, iter700, loss: 1.8512054681777954\n",
      "training loss :  1.826797153760669\n",
      "Finish epoch 1, time elapsed 141.33158588409424\n",
      "model saved for later use\n",
      "epoch2, iter0, loss: 1.393239974975586\n",
      "epoch2, iter100, loss: 1.730649709701538\n",
      "epoch2, iter200, loss: 1.4389915466308594\n",
      "epoch2, iter300, loss: 1.9298832416534424\n",
      "epoch2, iter400, loss: 1.0459494590759277\n",
      "epoch2, iter500, loss: 1.9167437553405762\n",
      "epoch2, iter600, loss: 1.7272109985351562\n",
      "epoch2, iter700, loss: 1.4967827796936035\n",
      "training loss :  1.7610484765421959\n",
      "Finish epoch 2, time elapsed 142.59571599960327\n",
      "model saved for later use\n",
      "epoch3, iter0, loss: 1.2547354698181152\n",
      "epoch3, iter100, loss: 1.3455109596252441\n",
      "epoch3, iter200, loss: 1.3554309606552124\n",
      "epoch3, iter300, loss: 1.7167160511016846\n",
      "epoch3, iter400, loss: 1.3778865337371826\n",
      "epoch3, iter500, loss: 1.8539535999298096\n",
      "epoch3, iter600, loss: 1.9012978076934814\n",
      "epoch3, iter700, loss: 2.0970234870910645\n",
      "training loss :  1.7270486917226546\n",
      "Finish epoch 3, time elapsed 141.6473891735077\n",
      "model saved for later use\n",
      "epoch4, iter0, loss: 1.3146538734436035\n",
      "epoch4, iter100, loss: 1.7139091491699219\n",
      "epoch4, iter200, loss: 1.5808403491973877\n",
      "epoch4, iter300, loss: 1.9557743072509766\n",
      "epoch4, iter400, loss: 1.2289360761642456\n",
      "epoch4, iter500, loss: 1.746028184890747\n",
      "epoch4, iter600, loss: 2.121424436569214\n",
      "epoch4, iter700, loss: 1.891862392425537\n",
      "training loss :  1.7025077693885373\n",
      "Finish epoch 4, time elapsed 141.11225366592407\n",
      "Validation loss after epoch 4, , loss: 1.692062515705824\n",
      "Accuracy on val after epoch 4, accuracy: 56.523551341740394\n",
      "IOU for class 11 on val after epoch4, iou: 4.797282576402781\n",
      "IOU for class 20 on val after epoch4, iou: 0.0\n",
      "IOU for class 24 on val after epoch4, iou: 0.0\n",
      "IOU for class 26 on val after epoch4, iou: 2.750443632382649\n",
      "IOU for class 33 on val after epoch4, iou: 0.0\n",
      "{7: 0.58590623437976, 8: 0.0, 11: 0.04797282576402781, 12: 0.0, 13: 0.0, 17: 0.0, 19: 0.0, 20: 0.0, 21: 0.29296313441598204, 22: 0.0, 23: 0.2982097260364892, 24: 0.0, 25: 0.0, 26: 0.02750443632382649, 27: 0.0, 28: 0.0, 31: 0.0, 32: 0.0, 33: 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved for later use\n",
      "epoch5, iter0, loss: 1.108170509338379\n",
      "epoch5, iter100, loss: 1.3963220119476318\n",
      "epoch5, iter200, loss: 1.477155089378357\n",
      "epoch5, iter300, loss: 1.8315258026123047\n",
      "epoch5, iter400, loss: 1.5283348560333252\n",
      "epoch5, iter500, loss: 1.6616638898849487\n",
      "epoch5, iter600, loss: 1.1232792139053345\n",
      "epoch5, iter700, loss: 1.1316288709640503\n",
      "training loss :  1.653786531379146\n",
      "Finish epoch 5, time elapsed 140.6960587501526\n",
      "model saved for later use\n",
      "epoch6, iter0, loss: 1.1503643989562988\n",
      "epoch6, iter100, loss: 1.3163657188415527\n",
      "epoch6, iter200, loss: 1.3047038316726685\n",
      "epoch6, iter300, loss: 1.8037893772125244\n",
      "epoch6, iter400, loss: 1.3949053287506104\n",
      "epoch6, iter500, loss: 1.5280418395996094\n",
      "epoch6, iter600, loss: 1.3044707775115967\n",
      "epoch6, iter700, loss: 1.6548054218292236\n",
      "training loss :  1.6452011153582604\n",
      "Finish epoch 6, time elapsed 141.68574857711792\n",
      "model saved for later use\n",
      "epoch7, iter0, loss: 1.3869075775146484\n",
      "epoch7, iter100, loss: 1.2664563655853271\n",
      "epoch7, iter200, loss: 1.5976523160934448\n",
      "epoch7, iter300, loss: 1.9615073204040527\n",
      "epoch7, iter400, loss: 1.4220240116119385\n",
      "epoch7, iter500, loss: 2.382317543029785\n",
      "epoch7, iter600, loss: 1.2859340906143188\n",
      "epoch7, iter700, loss: 1.3730405569076538\n",
      "training loss :  1.6245324352095205\n",
      "Finish epoch 7, time elapsed 140.85870599746704\n",
      "model saved for later use\n",
      "epoch8, iter0, loss: 0.9686021208763123\n",
      "epoch8, iter100, loss: 1.4773805141448975\n",
      "epoch8, iter200, loss: 1.0891379117965698\n",
      "epoch8, iter300, loss: 1.8030149936676025\n",
      "epoch8, iter400, loss: 1.54922616481781\n",
      "epoch8, iter500, loss: 1.631137728691101\n",
      "epoch8, iter600, loss: 0.9792295694351196\n",
      "epoch8, iter700, loss: 1.845022439956665\n",
      "training loss :  1.602723379689519\n",
      "Finish epoch 8, time elapsed 140.7702555656433\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    \n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "all_val_accuracies = []\n",
    "all_val_iou = []\n",
    "all_val_iou_class = {}\n",
    "startingValLoss = 10000000.0\n",
    "curEpoch = 0\n",
    "epochList = []\n",
    "\n",
    "        \n",
    "def train():\n",
    "    global curEpoch\n",
    "    global startingValLoss\n",
    "    while(curEpoch < epochs):\n",
    "        model.train()\n",
    "        curEpochLoss = []\n",
    "        ts = time.time()\n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda()   # Move your inputs onto the gpu\n",
    "                labels = Y.cuda() # Move your labels onto the gpu\n",
    "                targets_onehot = tar.cuda()\n",
    "            else:\n",
    "                inputs, labels, targets_onehot = X, Y, tar# Unpack variables into inputs and labels\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #loss = weighted_ce_loss(outputs, targets_onehot, weighted=True)\n",
    "            curEpochLoss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 100 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(curEpoch, iter, loss.item(), time.time() - ts))\n",
    "        curEpochLoss = sum(curEpochLoss)/len(curEpochLoss)\n",
    "        print('training loss : ', curEpochLoss)\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(curEpoch, time.time() - ts))\n",
    "        \n",
    "        if(curEpoch % 4 == 0):\n",
    "            epochList.append(curEpoch)\n",
    "            all_train_losses.append(curEpochLoss)\n",
    "            val_loss, val_accuracy, val_iou_net, val_iou_net_class_wise = val(curEpoch)\n",
    "            all_val_losses.append(val_loss)\n",
    "            all_val_accuracies.append(val_accuracy)\n",
    "            all_val_iou.append(val_iou_net)\n",
    "            for c in val_iou_net_class_wise:\n",
    "                if(c not in all_val_iou_class):\n",
    "                    all_val_iou_class[c] = []\n",
    "                all_val_iou_class[c].append(val_iou_net_class_wise[c])\n",
    "\n",
    "            plotTwoGraphs(epochList, all_train_losses, all_val_losses)\n",
    "            plotGraph(epochList, all_val_accuracies, 'validation_accuracy')\n",
    "            plotGraph(epochList, all_val_iou, 'average_iou')\n",
    "            plotIousClassWise(epochList, all_val_iou_class)\n",
    "\n",
    "            if(val_loss < startingValLoss):\n",
    "                startingValLoss = val_loss\n",
    "                results = {}\n",
    "                results['accuracy'] = val_accuracy\n",
    "                results['iou_net'] = val_iou_net\n",
    "                results['iou_net_class_wise'] = val_iou_net_class_wise\n",
    "                results['total_loss'] = val_loss\n",
    "                results['epoch'] = curEpoch\n",
    "                results['epoch_list'] = epochList\n",
    "                with open(MYDIR + '/results_val.txt', 'wt') as out:\n",
    "                    pprint(results, stream=out)\n",
    "                torch.save({'model_state_dict' : model.state_dict()}, MYDIR + '/best_model')\n",
    "                test(1)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict' : model.state_dict(),\n",
    "            'optimizer_state_dict' : optimizer.state_dict(),\n",
    "            'data' : {\n",
    "                'all_train_losses' : all_train_losses,\n",
    "                'all_val_accuracies' : all_val_accuracies,\n",
    "                'all_val_losses' : all_val_losses,\n",
    "                'all_val_iou' : all_val_iou,\n",
    "                'all_val_iou_class' : all_val_iou_class,\n",
    "                'epoch' : curEpoch,\n",
    "                'starting_val_loss' : startingValLoss,\n",
    "                'epoch_list' : epochList\n",
    "            }\n",
    "        }, MYDIR+'/'+'model_params')\n",
    "        \n",
    "        print('model saved for later use')\n",
    "        \n",
    "        curEpoch += 1\n",
    "    \n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    total_loss = []\n",
    "    acc_num = 0\n",
    "    acc_den = 0\n",
    "    #iou_num = len(iou_classes)*[0] \n",
    "    #iou_den = len(iou_classes)*[0] \n",
    "    iou_num = {}\n",
    "    iou_den = {}\n",
    "    \n",
    "    for iter, (X_val, tar_val, Y_val) in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            inputs_val = X_val.cuda()   # Move your inputs onto the gpu\n",
    "            labels_val = Y_val.cuda() # Move your labels onto the gpu\n",
    "            tar_val = tar_val.cuda()\n",
    "        else:\n",
    "            inputs_val, labels_val, tar_val = X_val, Y_val, tar_val# Unpack variables into inputs and labels\n",
    "\n",
    "        outputs_val = model(inputs_val)\n",
    "        \n",
    "        _, preds = torch.max(outputs_val, 1)\n",
    "        \n",
    "        #loss_val = weighted_ce_loss(outputs_val, tar_val, weighted=True)\n",
    "        loss_val = criterion(outputs_val, labels_val).item()\n",
    "        \n",
    "        preds_cpu = preds.cpu()\n",
    "        Y_cpu = Y_val.cpu()\n",
    "        \n",
    "        total_loss.append(loss_val)\n",
    "        \n",
    "        nn, dd = pixel_acc(preds_cpu, Y_cpu)\n",
    "        acc_num += nn\n",
    "        acc_den += dd\n",
    "        \n",
    "        for iou_cc_idx in range(len(useful_ids)):\n",
    "            i_nn, i_dd = iou(preds_cpu, Y_cpu, useful_ids[iou_cc_idx])\n",
    "            if useful_ids[iou_cc_idx] not in iou_num:\n",
    "                iou_num[useful_ids[iou_cc_idx]] = 0\n",
    "                iou_den[useful_ids[iou_cc_idx]] = 0\n",
    "            iou_num[useful_ids[iou_cc_idx]] += i_nn\n",
    "            iou_den[useful_ids[iou_cc_idx]] += i_dd\n",
    "            \n",
    "        del inputs_val\n",
    "        del labels_val\n",
    "        del loss_val\n",
    "    total_loss = sum(total_loss)/len(total_loss)\n",
    "    print(\"Validation loss after epoch {}, , loss: {}\".format(epoch, total_loss))\n",
    "    print(\"Accuracy on val after epoch {}, accuracy: {}\".format(epoch, 100*acc_num/acc_den))\n",
    "    for iou_cc_idx in range(len(iou_classes)):\n",
    "        print(\"IOU for class {} on val after epoch{}, iou: {}\".format(iou_classes[iou_cc_idx], epoch, 100*iou_num[iou_classes[iou_cc_idx]]/iou_den[iou_classes[iou_cc_idx]]))\n",
    "\n",
    "    iou_net_class_wise = dict((c, iou_num[c]/iou_den[c]) for c in iou_num)\n",
    "    print(iou_net_class_wise)\n",
    "    accuracy = acc_num / acc_den\n",
    "    iou_net_num = 0\n",
    "    iou_net_den = 0\n",
    "    for c in iou_num:\n",
    "        iou_net_num += iou_num[c]\n",
    "        iou_net_den += iou_den[c]\n",
    "    iou_net = iou_net_num/iou_net_den\n",
    "\n",
    "    return total_loss, accuracy, iou_net, iou_net_class_wise\n",
    "\n",
    "def colorMap(a, i):\n",
    "    return idsColor[a][i]\n",
    "\n",
    "def test(numFigures):\n",
    "    #fcn_model.load_state_dict(torch.load(MYDIR + '/best_model'))\n",
    "    #model = torch.load(MYDIR + '/best_model')\n",
    "    #model.cuda()\n",
    "    model.eval()\n",
    "    dataiter = iter(test_loader)\n",
    "    i = 0\n",
    "    while(i < numFigures):\n",
    "        i += 1\n",
    "        X_test, img_full, Y_test = dataiter.next()\n",
    "        if use_gpu:\n",
    "            inputs_test = X_test.cuda()   # Move your inputs onto the gpu\n",
    "            labels_test = Y_test.cuda() # Move your labels onto the gpu\n",
    "            #img_full_test = img_full.cuda()\n",
    "        else:\n",
    "            inputs_test, labels_test = X_test, Y_test# Unpack variables into inputs and labels\n",
    "            #img_full_test = img_full\n",
    "\n",
    "        outputs = model(inputs_test)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        inputs_test = inputs_test.permute(0, 2, 3, 1)\n",
    "        #img_full_test = img_full_test.permute(0, 2, 3, 1)\n",
    "\n",
    "        f = plt.figure(figsize=(16,8))\n",
    "        ax = f.add_subplot(121)\n",
    "        ax2 = f.add_subplot(122)\n",
    "\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        ax.imshow(torchvision.utils.make_grid(-1*inputs_test.cpu()))\n",
    "        \n",
    "\n",
    "\n",
    "        preds = preds.cpu().numpy()\n",
    "\n",
    "        preds0 = np.vectorize(colorMap)(preds, 0)\n",
    "        preds1 = np.vectorize(colorMap)(preds, 1)\n",
    "        preds2 = np.vectorize(colorMap)(preds, 2)\n",
    "\n",
    "        preds = torch.from_numpy(np.transpose(np.concatenate((preds0, preds1, preds2), 0), (1,2,0)))\n",
    "\n",
    "        #plt.subplot(1, 2, 2)\n",
    "        ax2.imshow(torchvision.utils.make_grid(preds.cpu()))\n",
    "        \n",
    "        plt.savefig(MYDIR+'/test.png',dpi=300)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     X_test = X_test.permute(0, 2, 3, 1)\n",
    "#     plt.imshow(torchvision.utils.make_grid(-1*X_test))\n",
    "#     outputs = model(X_test)\n",
    "#     _, preds = torch.max(outputs, 1)\n",
    "#     print(preds.Size())\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "              \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #test(10)\n",
    "    try:\n",
    "        checkpoint = torch.load(MYDIR+'/'+'model_params')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.cuda()\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        #optimizer.cuda()\n",
    "        all_train_losses = checkpoint['data']['all_train_losses']\n",
    "        all_val_losses = checkpoint['data']['all_val_losses']\n",
    "        all_val_accuracies = checkpoint['data']['all_val_accuracies']\n",
    "        all_val_iou = checkpoint['data']['all_val_iou']\n",
    "        all_val_iou_class = checkpoint['data']['all_val_iou_class']\n",
    "        startingValLoss = checkpoint['data']['starting_val_loss']\n",
    "        curEpoch = checkpoint['data']['epoch'] + 1\n",
    "        epochList = checkpoint['data']['epoch_list']\n",
    "        print('starting with epoch : ', curEpoch)\n",
    "    except:\n",
    "        print('here')\n",
    "        pass\n",
    "    print(useful_ids)\n",
    "    train()\n",
    "    \n",
    "    \n",
    "    #train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
