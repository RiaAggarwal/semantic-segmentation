{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CityScapesDataset(csv_file='./Data/train.csv')\n",
    "val_dataset = CityScapesDataset(csv_file='./Data/val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='./Data/test.csv')\n",
    "\n",
    "_batch_size = 8\n",
    "_num_workers = 4\n",
    "iou_classes = [11, 20, 24, 26, 33]\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=_batch_size,\n",
    "                          num_workers=_num_workers,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=_batch_size,\n",
    "                          num_workers=_num_workers,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=_batch_size,\n",
    "                          num_workers=_num_workers,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        #torch.nn.init.xavier_uniform(m.bias.data)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "epochs     = 100\n",
    "criterion = nn.CrossEntropyLoss()# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "fcn_model = FCN(n_class=n_class)\n",
    "# for name, params in fcn_model.named_parameters():\n",
    "#     print(name, params.shape, params.requires_grad)\n",
    "    \n",
    "fcn_model.apply(init_weights)\n",
    "#fcn_model = torch.load('best_model')\n",
    "\n",
    "optimizer = optim.Adam(fcn_model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Results/fcn folder already exists.\n"
     ]
    }
   ],
   "source": [
    "modelName = 'fcn'\n",
    "MYDIR = \"./Results\" + \"/\" + modelName\n",
    "CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MYDIR)\n",
    "    print(\"created folder : \", MYDIR)\n",
    "else:\n",
    "    print(MYDIR, \"folder already exists.\")\n",
    "\n",
    "def plotTwoGraphs(base, train_metrics, val_metrics):\n",
    "    plt.figure()\n",
    "    plt.plot(base, train_metrics)\n",
    "    plt.plot(base, val_metrics)\n",
    "    plt.gca().legend(('train','validation'))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.savefig(MYDIR + '/loss.png')\n",
    "\n",
    "def plotGraph(base, metrics, name):\n",
    "    plt.figure()\n",
    "    plt.plot(base, metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(name)\n",
    "    plt.title(name + ' vs Epochs')\n",
    "    plt.savefig(MYDIR + '/' + name + '.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, {0: 15228281, 1: 1040357, 2: 5532990, 3: 621145, 4: 9056313}, 673.5386364459991)\n",
      "Test loss after epoch 0, , loss: 673.5386364459991\n",
      "Accuracy on test after epoch 0, accuracy: \n",
      "yayyy, code reached till here!\n",
      "epoch0, iter0, loss: 3.9734296798706055\n",
      "epoch0, iter100, loss: 2.594252347946167\n",
      "epoch0, iter200, loss: 1.7255687713623047\n",
      "epoch0, iter300, loss: 2.404722213745117\n",
      "training loss :  1.9123156975994828\n",
      "Finish epoch 0, time elapsed 97.90253400802612\n",
      "Validation loss after epoch 0, , loss: 1.8384951986963787\n",
      "Accuracy on val after epoch 0, accuracy: 55.39011873433441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FCN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvTranspose2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1, iter0, loss: 1.6959939002990723\n",
      "epoch1, iter100, loss: 2.809593677520752\n",
      "epoch1, iter200, loss: 1.3752617835998535\n",
      "epoch1, iter300, loss: 2.2059478759765625\n",
      "training loss :  1.621572133834644\n",
      "Finish epoch 1, time elapsed 95.41624569892883\n",
      "Validation loss after epoch 1, , loss: 1.5998298573115515\n",
      "Accuracy on val after epoch 1, accuracy: 60.74135920177723\n",
      "epoch2, iter0, loss: 1.2041064500808716\n",
      "epoch2, iter100, loss: 1.9458788633346558\n",
      "epoch2, iter200, loss: 1.2404119968414307\n",
      "epoch2, iter300, loss: 1.8474711179733276\n",
      "training loss :  1.5758285370244776\n",
      "Finish epoch 2, time elapsed 98.28761148452759\n",
      "Validation loss after epoch 2, , loss: 1.4063781726927984\n",
      "Accuracy on val after epoch 2, accuracy: 67.35423389088349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3, iter0, loss: 1.1595466136932373\n",
      "epoch3, iter100, loss: 2.0788395404815674\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    fcn_model = fcn_model.cuda()\n",
    "    \n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "all_val_accuracies = []\n",
    "all_val_iou = []\n",
    "all_val_iou_class = {}\n",
    "\n",
    "\n",
    "        \n",
    "def train():\n",
    "    startingValLoss = 10000000.0\n",
    "    for epoch in range(epochs):\n",
    "        fcn_model.train()\n",
    "        curEpochLoss = []\n",
    "        ts = time.time()\n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda()   # Move your inputs onto the gpu\n",
    "                labels = Y.cuda() # Move your labels onto the gpu\n",
    "            else:\n",
    "                inputs, labels = X, Y# Unpack variables into inputs and labels\n",
    "            outputs = fcn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            curEpochLoss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 100 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item(), time.time() - ts))\n",
    "        curEpochLoss = sum(curEpochLoss)/len(curEpochLoss)\n",
    "        print('training loss : ', curEpochLoss)\n",
    "        all_train_losses.append(curEpochLoss)\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        \n",
    "        \n",
    "        val_loss, val_accuracy, val_iou_net, val_iou_net_class_wise = val(epoch)\n",
    "        all_val_losses.append(val_loss)\n",
    "        all_val_accuracies.append(val_accuracy)\n",
    "        all_val_iou.append(val_iou_net)\n",
    "        for c in val_iou_net_class_wise:\n",
    "            if(c not in all_val_iou_class):\n",
    "                all_val_iou_class[c] = []\n",
    "            all_val_iou_class[c].append(val_iou_net_class_wise[c])\n",
    "        \n",
    "        plotTwoGraphs([i for i in range(epoch+1)], all_train_losses, all_val_losses)\n",
    "        plotGraph([i for i in range(epoch+1)], all_val_accuracies, 'validation_accuracy')\n",
    "        plotGraph([i for i in range(epoch+1)], all_val_iou, 'average_iou')\n",
    "        for c in all_val_iou_class:\n",
    "            plotGraph([i for i in range(epoch+1)], all_val_iou_class[c], 'iou'+str(c))\n",
    "        \n",
    "        if(val_loss < startingValLoss):\n",
    "            startingValLoss = val_loss\n",
    "            results = {}\n",
    "            results['accuracy'] = val_accuracy\n",
    "            results['iou_net'] = val_iou_net\n",
    "            results['iou_net_class_wise'] = val_iou_net_class_wise\n",
    "            results['total_loss'] = val_loss\n",
    "            results['epoch'] = epoch\n",
    "            with open(MYDIR + '/results_val.txt', 'wt') as out:\n",
    "                pprint(results, stream=out)\n",
    "            torch.save(fcn_model, MYDIR + '/best_model')\n",
    "            #test(epoch)\n",
    "    \n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    fcn_model.eval()\n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    total_loss = []\n",
    "    acc_num = 0\n",
    "    acc_den = 0\n",
    "    #iou_num = len(iou_classes)*[0] \n",
    "    #iou_den = len(iou_classes)*[0] \n",
    "    iou_num = {}\n",
    "    iou_den = {}\n",
    "    \n",
    "    for iter, (X_val, tar_val, Y_val) in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            inputs_val = X_val.cuda()   # Move your inputs onto the gpu\n",
    "            labels_val = Y_val.cuda() # Move your labels onto the gpu\n",
    "        else:\n",
    "            inputs_val, labels_val = X_val, Y_val# Unpack variables into inputs and labels\n",
    "\n",
    "        outputs_val = fcn_model(inputs_val)\n",
    "        \n",
    "        _, preds = torch.max(outputs_val, 1)\n",
    "        \n",
    "        loss_val = criterion(outputs_val, labels_val).item()\n",
    "        \n",
    "        preds_cpu = preds.cpu()\n",
    "        Y_cpu = Y_val.cpu()\n",
    "        \n",
    "        total_loss.append(loss_val)\n",
    "        \n",
    "        nn, dd = pixel_acc(preds_cpu, Y_cpu)\n",
    "        acc_num += nn\n",
    "        acc_den += dd\n",
    "        \n",
    "        for iou_cc_idx in range(len(iou_classes)):\n",
    "            i_nn, i_dd = iou(preds_cpu, Y_cpu, iou_classes[iou_cc_idx])\n",
    "            if iou_cc_idx not in iou_num:\n",
    "                iou_num[iou_cc_idx] = 0\n",
    "                iou_den[iou_cc_idx] = 0\n",
    "            iou_num[iou_cc_idx] += i_nn\n",
    "            iou_den[iou_cc_idx] += i_dd\n",
    "            \n",
    "        del inputs_val\n",
    "        del labels_val\n",
    "        del loss_val\n",
    "    total_loss = sum(total_loss)/len(total_loss)\n",
    "    print(\"Validation loss after epoch {}, , loss: {}\".format(epoch, total_loss))\n",
    "    print(\"Accuracy on val after epoch {}, accuracy: {}\".format(epoch, 100*acc_num/acc_den))\n",
    "#     for iou_cc_idx in range(len(iou_classes)):\n",
    "#         print(\"IOU for class {} on val after epoch{}, iou: {}\".format(iou_classes[iou_cc_idx], epoch, 100*iou_num[iou_cc_idx]/iou_den[iou_cc_idx]))\n",
    "\n",
    "    iou_net_class_wise = dict((c, iou_num[c]/iou_den[c]) for c in iou_num)\n",
    "    accuracy = acc_num / acc_den\n",
    "    iou_net_num = 0\n",
    "    iou_net_den = 0\n",
    "    for c in iou_num:\n",
    "        iou_net_num += iou_num[c]\n",
    "        iou_net_den += iou_den[c]\n",
    "    iou_net = iou_net_num/iou_net_den\n",
    "\n",
    "    return total_loss, accuracy, iou_net, iou_net_class_wise\n",
    "    \n",
    "def test(epoch):\n",
    "    fcn_model.eval()\n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    total_loss = 0\n",
    "    acc_num = 0\n",
    "    acc_den = 0\n",
    "#     iou_num = len(iou_classes)*[0] \n",
    "#     iou_den = len(iou_classes)*[0]\n",
    "    iou_num = {}\n",
    "    iou_den = {}\n",
    "    \n",
    "    for iter, (X_val, tar_val, Y_val) in enumerate(test_loader):\n",
    "        if use_gpu:\n",
    "            inputs_val = X_val.cuda()   # Move your inputs onto the gpu\n",
    "            labels_val = Y_val.cuda() # Move your labels onto the gpu\n",
    "        else:\n",
    "            inputs_val, labels_val = X_val, Y_val# Unpack variables into inputs and labels\n",
    "\n",
    "        outputs_val = fcn_model(inputs_val)\n",
    "        \n",
    "        _, preds = torch.max(outputs_val, 1)\n",
    "        \n",
    "        loss_val = criterion(outputs_val, labels_val).item()\n",
    "        \n",
    "        preds_cpu = preds.cpu()\n",
    "        Y_cpu = Y_val.cpu()\n",
    "        \n",
    "        total_loss += loss_val\n",
    "        \n",
    "        nn, dd = pixel_acc(preds_cpu, Y_cpu)\n",
    "        acc_num += nn\n",
    "        acc_den += dd\n",
    "        \n",
    "        for iou_cc_idx in range(len(iou_classes)):\n",
    "            i_nn, i_dd = iou(preds_cpu, Y_cpu, iou_classes[iou_cc_idx])\n",
    "            if iou_cc_idx not in iou_num:\n",
    "                iou_num[iou_cc_idx] = 0\n",
    "                iou_den[iou_cc_idx] = 0\n",
    "            iou_num[iou_cc_idx] += i_nn\n",
    "            iou_den[iou_cc_idx] += i_dd\n",
    "            \n",
    "        del inputs_val\n",
    "        del labels_val\n",
    "        del loss_val\n",
    "    print((acc_num, acc_den, iou_num, iou_den, total_loss))\n",
    "        \n",
    "    print(\"Test loss after epoch {}, , loss: {}\".format(epoch, total_loss))\n",
    "    print(\"Accuracy on test after epoch {}, accuracy: {}\".format(epoch, ''))\n",
    "#     for iou_cc_idx in range(len(iou_classes)):\n",
    "#         print(\"IOU for class {} on val after epoch{}, iou: {}\".format(iou_classes[iou_cc_idx], epoch, 100*iou_num[iou_cc_idx]/iou_den[iou_cc_idx]))\n",
    "\n",
    "    iou_net_class_wise = dict((c, iou_num[c]/iou_den[c]) for c in iou_num)\n",
    "    for c in iou_num:\n",
    "        try:\n",
    "            iou_net_class_wise[c] = iou_num[c]/iou_den[c]\n",
    "        except:\n",
    "            iou_net_class_wise[c] = 0.0\n",
    "        \n",
    "    try:\n",
    "        accuracy = acc_num / acc_den\n",
    "    except:\n",
    "        accuracy = 0\n",
    "        \n",
    "    iou_net_num = 0\n",
    "    iou_net_den = 0\n",
    "    for c in iou_num:\n",
    "        iou_net_num += iou_num[c]\n",
    "        iou_net_den += iou_den[c]\n",
    "    try:\n",
    "        iou_net = iou_net_num/iou_net_den\n",
    "    except:\n",
    "        iou_net = 0.0\n",
    "    results = {}\n",
    "    results['accuracy'] = accuracy\n",
    "    results['iou_net'] = iou_net\n",
    "    results['iou_net_class_wise'] = iou_net_class_wise\n",
    "    results['total_loss'] = total_loss\n",
    "    results['epoch'] = epoch\n",
    "    print('yayyy, code reached till here!')\n",
    "    with open(MYDIR + '/results_test.txt', 'wt') as out:\n",
    "        pprint(results, stream=out)\n",
    "              \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test(0)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
